# -*- coding: utf-8 -*-
"""Ejercicio 1

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1TAZGSnksP-k-VMaor72n4yfGqEcgy5Ik

# Feedforward Neural Networks

Importing some python libraries
"""

from google.colab import drive
drive.mount('/content/gdrive')

"""2"""

import requests 
file_url = "https://sid.erda.dk/public/archives/daaeac0d7ce1152aea9b61d9f1e19370/GTSRB_Final_Training_Images.zip"
r = requests.get(file_url, stream = True)
with open("/content/gdrive/My Drive/GTSRB_Final_Training_Images.zip", "wb") as file:
  for block in r.iter_content(chunk_size = 1024):
      if block:
        file.write(block)

"""3"""

!unzip  '/content/gdrive/MyDrive/GTSRB_Final_Training_Images.zip' -d '/content/gdrive/MyDrive/GTSRB/'

ROOT_DIR = '/content/gdrive/MyDive/GTSRB/GTSRB/'

label_class={
    0: '20_speed',
    1: '30_speed',
    2: '50_speed',
    3: '60_speed',
    4: '70_speed',
    5: '80_speed',
    6: '80_lifted',
    7: '100_speed',
    8: '120_speed',
    9: 'no_overtalking_general',
    10: 'no_overtalking_trucks',
    11: 'right_of_way_crossing',
    12: 'right_of_way_general',
    13: 'give_way',
    14: 'stop',
    15: 'no_way_general',
    16: 'no_way_trucks',
    17: 'no_way_one_way',
    18: 'attention_general',
    19: 'attention_left_turn',
    20: 'attention_right_turn',
    21: 'attention_curvy',
    22: 'attention_bumpers',
    23: 'attention_slippery',
    24: 'attention_bottleneck',
    25: 'attention_construction',
    26: 'attention_traffic_light',
    27: 'attention_pedestrian',
    28: 'attention_children',
    29: 'attention_bikes',
    30: 'attention_snowflake',
    31: 'attention_deer',
    32: 'lifted_general',
    33: 'turn_right',
    34: 'turn_left',
    35: 'turn_straight',
    36: 'turn_straight_right',
    37: 'turn_straight_left',
    38: 'turn_right_down',
    39: 'turn_left_down',
    40: 'turn_circle',
    41: 'lifted_no_overtaking_general',
    42: 'lifted_no_overtaking_trucks'
}

import numpy as np
import cv2
import matplotlib.pyplot as plt
import torch, torchvision
from glob import glob
train_folders = sorted(glob(ROOT_DIR + 'Final_Training/images/*'))
print(len(train_folders))

def load_image(img_path, resize=True):
    img= cv2.cvtColor(cv2.imread(img_path), cv2.COLOR_BAYER_BG2BGR)
    if resize:
        img = cv2.resize(img, (20,20), interpolation= cv2.INTER_AREA)
    return img

def show_image(img_path):
    img=load_image(img_path)
    plt.imshow(img)
    plt.axis('off')

def show_sign_grid(image_paths):
    images = [load_image(img) for img in image_paths]
    fig, axs =plt.subplots(4, 11, figsize=(24,12))
    axs = axs.flatten()
    [axi.set_axis_off() for axi in axs]
    for img, ax in zip(images, axs):
        ax.axis('off')
        ax.imshow(img)
    ax.axis('off')
    plt.show()

sample_images = [np.random.choice(glob(f'{tf}/*ppm')) for tf in train_folders]
show_sign_grid(sample_images)

import os
training_images = []
training_labels = []
for i, cls_index in enumerate(label_class):
    image_paths = np.array(glob(f'{train_folders[cls_index]}/*.ppm'))
    class_names = label_class[i]
    print('Class ' + f'{class_names}: {len(image_paths)}')
    for image_path in image_paths:
        img = cv2.cvtColor(cv2.imread(image_path), cv2.COLOR_BAYER_BG2BGR)
        img = cv2.resize(img, (64, 64), interpolation= cv2.INTER_AREA)
        training_images.append(img)
        training_labels.append(class_names)

import tensorflow as tf
from keras import datasets, layers, models

train_images = np.array(training_images)/255.0

model = models.Sequential()
model.add(layers.Conv2D(32, (3,3), activation='relu', input_shape=(64, 64, 3)))
model.add(layers.MaxPooling2D((2,2)))
model.add(layers.Conv2D(64,(3, 3), activation='relu'))
model.add(layers.MaxPooling2D((2,2)))
model.add(layers.Conv2D(64,(3, 3), activation='relu'))
model.add(layers.Flatten)
model.add(layers.Dense(64, activation='relu'))
model.add(layers.Dense(43))

model.compile(optimizer='adam',
              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),
              metrics=['accuracy'])

training_labels = []
for i, cls_index in enumerate(label_class):
    image_paths = np.array(glob(f'{train_folders[cls_index]}/*.ppm'))
    class_names = i
    for image_path in image_paths:
        training_labels.append(class_names)
training_labels = np.array(training_labels)
print(training_labels)

history = model.fit(train_images, training_labels, epochs=10)

model.save(ROOT_DIR + 'my_model')

prediction = model.predict(train_images)

plt.imshow(train_images[22650])
plt.axis('off')
print(train_images[22650].shape)
print(len(prediction))
print(label_class[np.argmax(prediction[22650])])

trained_model =models.load_model(ROOT_DIR + 'my_model')
print(trained_model.summary())

"""Codigo 2"""

from google.colab import drive
drive.mount('/content/gdrive')

import requests 
file_url = "https://sid.erda.dk/public/archives/daaeac0d7ce1152aea9b61d9f1e19370/GTSRB_Final_Training_Images.zip"
r = requests.get(file_url, stream = True)
with open("/content/gdrive/My Drive/GTSRB_Final_Training_Images.zip", "wb") as file:
  for block in r.iter_content(chunk_size = 1024):
      if block:
        file.write(block)

!unzip  '/content/gdrive/MyDrive/GTSRB_Final_Training_Images.zip' -d '/content/gdrive/MyDrive/GTSRB/'

ROOT_DIR = '/content/gdrive/My Dive/GTSRB/GTSRB/'

label_class={
    0: '20_speed',
    1: '30_speed',
    2: '50_speed',
    3: '60_speed',
    4: '70_speed',
    5: '80_speed',
    6: '80_lifted',
    7: '100_speed',
    8: '120_speed',
    9: 'no_overtalking_general',
    10: 'no_overtalking_trucks',
    11: 'right_of_way_crossing',
    12: 'right_of_way_general',
    13: 'give_way',
    14: 'stop',
    15: 'no_way_general',
    16: 'no_way_trucks',
    17: 'no_way_one_way',
    18: 'attention_general',
    19: 'attention_left_turn',
    20: 'attention_right_turn',
    21: 'attention_curvy',
    22: 'attention_bumpers',
    23: 'attention_slippery',
    24: 'attention_bottleneck',
    25: 'attention_construction',
    26: 'attention_traffic_light',
    27: 'attention_pedestrian',
    28: 'attention_children',
    29: 'attention_bikes',
    30: 'attention_snowflake',
    31: 'attention_deer',
    32: 'lifted_general',
    33: 'turn_right',
    34: 'turn_left',
    35: 'turn_straight',
    36: 'turn_straight_right',
    37: 'turn_straight_left',
    38: 'turn_right_down',
    39: 'turn_left_down',
    40: 'turn_circle',
    41: 'lifted_no_overtaking_general',
    42: 'lifted_no_overtaking_trucks'
}

import numpy as np
import cv2
import matplotlib.pyplot as plt
import torch, torchvision
from glob import glob
train_folders = sorted(glob(ROOT_DIR + 'Final_Training/images/*'))
print(len(train_folders))


def load_image(img_path, resize=True):
    img= cv2.cvtColor(cv2.imread(img_path), cv2.COLOR_BAYER_BG2BGR)
    if resize:
        img = cv2.resize(img, (64,64), interpolation= cv2.INTER_AREA)
    return img

def show_image(img_path):
    img=load_image(img_path)
    plt.imshow(img)
    plt.axis('off')

def show_sign_grid(image_paths):
    images = [load_image(img) for img in image_paths]
    fig, axs =plt.subplots(4, 11, figsize=(24,12))
    axs = axs.flatten()
    [axi.set_axis_off() for axi in axs]
    for img, ax in zip(images, axs):
        ax.axis('off')
        ax.imshow(img)
    ax.axis('off')
    plt.show()



sample_images = [np.random.choice(glob(f'{tf}/*ppm')) for tf in train_folders]
show_sign_grid(sample_images)



import os
training_images = []
training_labels = []
for i, cls_index in enumerate(label_class):
    image_paths = np.array(glob(f'{train_folders[cls_index]}/*.ppm'))
    class_names = label_class[i]
    print('Class ' + f'{class_names}: {len(image_paths)}')
    for image_path in image_paths:
        img = cv2.cvtColor(cv2.imread(image_path), cv2.COLOR_BAYER_BG2BGR)
        img = cv2.resize(img, (64, 64), interpolation= cv2.INTER_AREA)
        training_images.append(img)
        training_labels.append(class_names)


import tensorflow as tf
from keras import datasets, layers, models

train_images = np.array(training_images)/255.0

model = models.Sequential()
model.add(layers.Conv2D(32, (3,3), activation='relu', input_shape=(64, 64, 3)))
model.add(layers.MaxPooling2D((2,2)))
model.add(layers.Conv2D(64,(3, 3), activation='relu'))
model.add(layers.MaxPooling2D((2,2)))
model.add(layers.Conv2D(64,(3, 3), activation='relu'))
model.add(layers.Flatten)
model.add(layers.Dense(64, activation='relu'))
model.add(layers.Dense(43))



model.compile(optimizer='adam',
              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),
              metrics=['accuracy'])

training_labels = []
for i, cls_index in enumerate(label_class):
    image_paths = np.array(glob(f'{train_folders[cls_index]}/*.ppm'))
    class_names = i
    for image_path in image_paths:
        training_labels.append(class_names)
training_labels = np.array(training_labels)
print(training_labels)


history = model.fit(train_images, training_labels, epochs=10)

model.save(ROOT_DIR + 'my_model')


prediction = model.predict(train_images)


plt.imshow(train_images[22650])
plt.axis('off')
print(train_images[22650].shape)
print(len(prediction))
print(label_class[np.argmax(prediction[22650])])


trained_model =models.load_model(ROOT_DIR + 'my_model')
print(trained_model.summary())